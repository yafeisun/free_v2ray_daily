#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨æ”¶é›†å™¨è„šæœ¬ - æ”¯æŒæ‰€æœ‰ç½‘ç«™çš„ç»Ÿä¸€å…¥å£
"""

import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.utils.logger import get_logger
from src.core.plugin_registry import get_registry
from src.utils.file_handler import FileHandler
from config.websites import WEBSITES


class UniversalCollector:
    """é€šç”¨æ”¶é›†å™¨ - æ”¯æŒæ‰€æœ‰ç½‘ç«™"""
    
    def __init__(self):
        self.logger = get_logger("universal_collector")
        self.file_handler = FileHandler()
        self.registry = get_registry()
    
    def run_site(self, site_key: str) -> bool:
        """è¿è¡ŒæŒ‡å®šç½‘ç«™çš„æ”¶é›†å™¨"""
        try:
            # æ£€æŸ¥ç½‘ç«™é…ç½®
            if site_key not in WEBSITES:
                self.logger.error(f"æœªæ‰¾åˆ°ç½‘ç«™é…ç½®: {site_key}")
                return False
            
            site_config = WEBSITES[site_key]
            if not site_config.get("enabled", True):
                self.logger.info(f"ç½‘ç«™å·²ç¦ç”¨: {site_key}")
                return True
            
            # æ£€æŸ¥æ”¶é›†å™¨æ’ä»¶
            collector_key = site_config.get("collector_key", site_key)
            if not self.registry.is_collector_available(collector_key):
                self.logger.error(f"æœªæ‰¾åˆ°æ”¶é›†å™¨æ’ä»¶: {collector_key}")
                return False
            
            # åˆ›å»ºæ”¶é›†å™¨å®ä¾‹
            collector = self.registry.create_collector_instance(collector_key, site_config)
            
            # å¼€å§‹æ”¶é›†
            self.logger.info(f"å¼€å§‹æ”¶é›† {site_key} çš„èŠ‚ç‚¹...")
            nodes = collector.collect()
            
            # æ”¶é›†V2Rayè®¢é˜…é“¾æ¥
            v2ray_links = []
            if hasattr(collector, 'last_article_url') and collector.last_article_url:
                v2ray_links = collector.get_v2ray_subscription_links(collector.last_article_url)
            
            # ä¿å­˜ç»“æœ
            self._save_results(site_key, collector, nodes, v2ray_links)
            
            self.logger.info(f"{site_key} æ”¶é›†å®Œæˆ: {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(v2ray_links)} ä¸ªè®¢é˜…é“¾æ¥")
            return True
            
        except Exception as e:
            self.logger.error(f"æ”¶é›† {site_key} å¤±è´¥: {str(e)}")
            return False
    
    def _save_results(self, site_key: str, collector, nodes: list, v2ray_links: list):
        """ä¿å­˜æ”¶é›†ç»“æœ"""
        try:
            # ä¿å­˜æ–‡ç« é“¾æ¥
            if hasattr(collector, 'last_article_url') and collector.last_article_url:
                article_file = f"result/{site_key}_article.txt"
                with open(article_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {site_key} æœ€æ–°æ–‡ç« é“¾æ¥\n")
                    f.write(f"# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"{collector.last_article_url}\n")
            
            # ä¿å­˜è®¢é˜…é“¾æ¥
            if v2ray_links:
                subscription_file = f"result/{site_key}_subscription.txt"
                with open(subscription_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {site_key} V2Rayè®¢é˜…é“¾æ¥\n")
                    f.write(f"# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# å…± {len(v2ray_links)} ä¸ªé“¾æ¥\n")
                    for i, link in enumerate(v2ray_links, 1):
                        f.write(f"{i}. {link}\n")
            
            # ä¿å­˜èŠ‚ç‚¹
            if nodes:
                nodes_file = f"result/{site_key}_nodes.txt"
                with open(nodes_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {site_key} èŠ‚ç‚¹åˆ—è¡¨\n")
                    f.write(f"# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"# å…± {len(nodes)} ä¸ªèŠ‚ç‚¹\n")
                    f.write("\n")
                    for node in nodes:
                        f.write(f"{node}\n")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
    
    def get_available_sites(self) -> list:
        """è·å–æ‰€æœ‰å¯ç”¨ç½‘ç«™"""
        available_sites = []
        for site_key, site_config in WEBSITES.items():
            if site_config.get("enabled", True):
                collector_key = site_config.get("collector_key", site_key)
                if self.registry.is_collector_available(collector_key):
                    available_sites.append(site_key)
        return available_sites
    
    def run_all_sites(self) -> dict:
        """è¿è¡Œæ‰€æœ‰ç½‘ç«™"""
        results = {}
        available_sites = self.get_available_sites()
        
        self.logger.info(f"å¼€å§‹è¿è¡Œ {len(available_sites)} ä¸ªç½‘ç«™...")
        
        for site_key in available_sites:
            success = self.run_site(site_key)
            results[site_key] = success
        
        success_count = sum(results.values())
        self.logger.info(f"è¿è¡Œå®Œæˆ: {success_count}/{len(available_sites)} ä¸ªç½‘ç«™æˆåŠŸ")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é€šç”¨æ”¶é›†å™¨è„šæœ¬")
    parser.add_argument("site", nargs="?", help="æŒ‡å®šè¦æ”¶é›†çš„ç½‘ç«™")
    parser.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰ç½‘ç«™")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç½‘ç«™")
    parser.add_argument("--exclude", nargs="+", help="æ’é™¤çš„ç½‘ç«™ï¼ˆä¸--allä¸€èµ·ä½¿ç”¨ï¼‰")
    parser.add_argument("--test", action="store_true", help="å¯ç”¨è¿é€šæ€§æµ‹è¯•")
    
    args = parser.parse_args()
    
    collector = UniversalCollector()
    
    # åˆ—å‡ºå¯ç”¨ç½‘ç«™
    if args.list:
        sites = collector.get_available_sites()
        print("å¯ç”¨ç½‘ç«™:")
        for site in sites:
            print(f"  - {site}")
        return
    
    # è¿è¡Œæ‰€æœ‰ç½‘ç«™
    if args.all:
        sites = collector.get_available_sites()
        if args.exclude:
            sites = [site for site in sites if site not in args.exclude]
        
        results = {}
        for site in sites:
            print(f"\nğŸš€ è¿è¡Œ {site}...")
            success = collector.run_site(site)
            results[site] = success
            if success:
                print(f"âœ… {site}: æˆåŠŸ")
            else:
                print(f"âŒ {site}: å¤±è´¥")
        
        # æ±‡æ€»ç»“æœ
        success_count = sum(results.values())
        print(f"\n{'='*60}")
        print(f"è¿è¡Œå®Œæˆ: {success_count}/{len(sites)} ä¸ªç½‘ç«™æˆåŠŸ")
        if success_count < len(sites):
            failed_sites = [site for site, success in results.items() if not success]
            print(f"å¤±è´¥ç½‘ç«™: {', '.join(failed_sites)}")
        return
    
    # è¿è¡ŒæŒ‡å®šç½‘ç«™
    if args.site:
        if args.site not in collector.get_available_sites():
            print(f"âŒ ç½‘ç«™ '{args.site}' ä¸å¯ç”¨")
            sys.exit(1)
        
        print(f"ğŸš€ è¿è¡Œ {args.site}...")
        success = collector.run_site(args.site)
        if success:
            print(f"âœ… {args.site}: æˆåŠŸ")
        else:
            print(f"âŒ {args.site}: å¤±è´¥")
            sys.exit(1)
        return
    
    # æ²¡æœ‰æŒ‡å®šå‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()