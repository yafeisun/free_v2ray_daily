#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæºèŠ‚ç‚¹æ”¶é›†å·¥ä½œæµå¼•æ“
é›†æˆå¤šç§æ•°æ®æºçš„é«˜çº§æ”¶é›†ç³»ç»Ÿ
"""

import asyncio
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from src.core.workflow_engine import WorkflowEngine
from src.core.node_validator import validate_nodes
from src.collectors.multi_source_collector import source_manager
from src.collectors.telegram_collector import create_telegram_collector
from src.collectors.github_collector import create_github_collector
from src.core.config_manager import get_config
from src.utils.logger import get_logger


class AdvancedWorkflowEngine(WorkflowEngine):
    """é«˜çº§å·¥ä½œæµå¼•æ“ - æ”¯æŒå¤šæºæ”¶é›†å’Œå®æ—¶éªŒè¯"""

    def __init__(self):
        super().__init__()
        self.config_manager = get_config()
        self.logger = get_logger("advanced_workflow")

        # æ³¨å†Œå¤šæºæ”¶é›†å™¨
        self._setup_multi_source_collectors()

    def _setup_multi_source_collectors(self):
        """è®¾ç½®å¤šæºæ”¶é›†å™¨"""
        # Telegramæ”¶é›†å™¨é…ç½®
        telegram_config = {
            "name": "TelegramèŠ‚ç‚¹æ”¶é›†",
            "enabled": os.getenv("TELEGRAM_ENABLED", "true").lower() == "true",
            "priority": 9,  # æœ€é«˜ä¼˜å…ˆçº§
            "bot_token": os.getenv("TELEGRAM_BOT_TOKEN"),
            "channels": [
                # é«˜è´¨é‡VPNé¢‘é“ç¤ºä¾‹ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ï¼‰
                "@vpn_nodes_daily",
                "@v2ray_free_nodes",
                "@proxy_updates_channel",
            ],
            "keywords": ["vmess", "vless", "trojan", "ss://", "èŠ‚ç‚¹"],
            "api_delay": 1.0,
            "max_messages": 50,
            "update_interval": 1800,  # 30åˆ†é’Ÿ
        }

        if telegram_config["bot_token"]:
            telegram_collector = create_telegram_collector(telegram_config)
            source_manager.register_collector(telegram_collector)

        # GitHubæ”¶é›†å™¨é…ç½®
        github_config = {
            "name": "GitHubé¡¹ç›®èšåˆ",
            "enabled": os.getenv("GITHUB_ENABLED", "true").lower() == "true",
            "priority": 8,  # é«˜ä¼˜å…ˆçº§
            "github_token": os.getenv("GITHUB_TOKEN"),
            "repositories": [
                {
                    "owner": "Loyalsoldier",
                    "repo": "v2ray_node_list",
                    "files": ["*.txt", "nodes/*.txt"],
                },
                {
                    "owner": "paimonhub",
                    "repo": "v2ray-free",
                    "files": ["*.txt", "*.md"],
                },
                {"owner": "ermaozi", "repo": "Free-VPN", "files": ["*.txt", "*.yaml"]},
            ],
            "timeout": 30,
            "max_files": 20,
        }

        github_collector = create_github_collector(github_config)
        source_manager.register_collector(github_collector)

        self.logger.info(f"å·²æ³¨å†Œ {len(source_manager.collectors)} ä¸ªå¤šæºæ”¶é›†å™¨")

    async def run_advanced_collection(
        self, sources: Optional[List[str]] = None
    ) -> bool:
        """è¿è¡Œé«˜çº§èŠ‚ç‚¹æ”¶é›†"""
        self.logger.info("ğŸš€ å¼€å§‹é«˜çº§èŠ‚ç‚¹æ”¶é›†...")
        start_time = datetime.now()

        try:
            # ä»å¤šæºæ”¶é›†èŠ‚ç‚¹
            nodes = await source_manager.collect_all_nodes()

            if not nodes:
                self.logger.warning("æœªä»ä»»ä½•æ•°æ®æºæ”¶é›†åˆ°èŠ‚ç‚¹")
                return False

            # è½¬æ¢ä¸ºèŠ‚ç‚¹URLåˆ—è¡¨
            node_urls = []
            for node in nodes:
                if isinstance(node, dict) and "url" in node:
                    node_urls.append(node["url"])
                elif isinstance(node, str):
                    node_urls.append(node)

            # å®æ—¶éªŒè¯èŠ‚ç‚¹è´¨é‡
            self.logger.info(f"å¼€å§‹éªŒè¯ {len(node_urls)} ä¸ªèŠ‚ç‚¹çš„è´¨é‡...")
            validated_results = await validate_nodes(
                node_urls,
                output_file=f"result/nodes_detailed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            )

            # ä¿å­˜é«˜è´¨é‡èŠ‚ç‚¹
            validated_urls = [r.url for r in validated_results]

            # ä¿å­˜åˆ°æ ‡å‡†æ ¼å¼
            date_str = datetime.now().strftime("%Y%m%d")
            date_dir = f"result/{date_str}"
            os.makedirs(date_dir, exist_ok=True)

            # ä¿å­˜è¯¦ç»†èŠ‚ç‚¹ä¿¡æ¯
            detailed_file = os.path.join(date_dir, "nodes_advanced.json")
            import json

            with open(detailed_file, "w", encoding="utf-8") as f:
                json.dump(
                    validated_results, f, indent=2, ensure_ascii=False, default=str
                )

            # ä¿å­˜æ ‡å‡†èŠ‚ç‚¹åˆ—è¡¨
            nodetotal_file = os.path.join(date_dir, "nodetotal.txt")
            with open(nodetotal_file, "w", encoding="utf-8") as f:
                for url in validated_urls:
                    f.write(f"{url}\\n")

            # ç»Ÿè®¡ä¿¡æ¯
            duration = (datetime.now() - start_time).total_seconds()
            online_count = len([r for r in validated_results if r.is_online])
            avg_quality = (
                sum(r.quality_score for r in validated_results) / len(validated_results)
                if validated_results
                else 0
            )

            # æ•°æ®æºç»Ÿè®¡
            source_stats = {}
            for node in nodes:
                source_type = node.get("source_type", "unknown")
                source_stats[source_type] = source_stats.get(source_type, 0) + 1

            self.logger.info("=" * 60)
            self.logger.info("ğŸ“Š é«˜çº§æ”¶é›†ç»Ÿè®¡:")
            self.logger.info(f"æ€»è€—æ—¶: {duration:.2f}ç§’")
            self.logger.info(f"åŸå§‹èŠ‚ç‚¹: {len(node_urls)} ä¸ª")
            self.logger.info(f"åœ¨çº¿èŠ‚ç‚¹: {online_count} ä¸ª")
            self.logger.info(f"å¹³å‡è´¨é‡: {avg_quality:.3f}")
            self.logger.info("ğŸ“ˆ æ•°æ®æºåˆ†å¸ƒ:")
            for source_type, count in source_stats.items():
                self.logger.info(f"  {source_type}: {count} ä¸ª")
self.logger.info("=" * 60)
        
        except Exception as e:
            self.logger.error(f"é«˜çº§æ”¶é›†å¼‚å¸¸: {str(e)}")
            return False
    
    def show_advanced_status(self):
        """æ˜¾ç¤ºé«˜çº§å·¥ä½œæµçŠ¶æ€"""
        self.logger.info("ğŸ”„ å¼€å§‹æ··åˆå·¥ä½œæµ...")
        start_time = datetime.now()

        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šä¼ ç»Ÿç½‘ç«™æ”¶é›†
            self.logger.info("ğŸ“¡ ç¬¬ä¸€é˜¶æ®µï¼šä¼ ç»Ÿç½‘ç«™æ”¶é›†")
            import asyncio

            loop = asyncio.get_event_loop()
            traditional_success = await loop.run_in_executor(
                None, lambda: self._run_collection_phase(sources)
            )

            # ç¬¬äºŒé˜¶æ®µï¼šé«˜çº§å¤šæºæ”¶é›†
            self.logger.info("ğŸš€ ç¬¬äºŒé˜¶æ®µï¼šé«˜çº§å¤šæºæ”¶é›†")
            advanced_success = await self.run_advanced_collection(sources)

            # ç¬¬ä¸‰é˜¶æ®µï¼šèŠ‚ç‚¹éªŒè¯å’Œè´¨é‡ç­›é€‰
            if enable_validation:
                self.logger.info("âš¡ ç¬¬ä¸‰é˜¶æ®µï¼šå®æ—¶èŠ‚ç‚¹éªŒè¯")
                await self._run_validation_phase()

            # ç¬¬å››é˜¶æ®µï¼šä¿å­˜å’ŒåŒæ­¥
            self.logger.info("ğŸ’¾ ç¬¬å››é˜¶æ®µï¼šä¿å­˜å’ŒåŒæ­¥")
            sync_success = self._run_save_sync_phase()

            # ç¬¬äº”é˜¶æ®µï¼šGitHubæ›´æ–°
            if update_github:
                self.logger.info("ğŸš€ ç¬¬äº”é˜¶æ®µï¼šGitHubæ›´æ–°")
                github_success = self._run_github_update_phase()

            # å·¥ä½œæµå®Œæˆ
            duration = (datetime.now() - start_time).total_seconds()
            self.logger.info("ğŸ‰ æ··åˆå·¥ä½œæµå®Œæˆ!")
            self.logger.info(f"æ€»è€—æ—¶: {duration:.2f}ç§’")

            return True

        except Exception as e:
            self.logger.error(f"æ··åˆå·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return False

    async def _run_validation_phase(self) -> bool:
        """è¿è¡ŒéªŒè¯é˜¶æ®µ"""
        try:
            # è¯»å–æœ€æ–°æ”¶é›†çš„èŠ‚ç‚¹
            date_str = datetime.now().strftime("%Y%m%d")
            nodetotal_file = f"result/{date_str}/nodetotal.txt"

            if not os.path.exists(nodetotal_file):
                self.logger.warning(f"èŠ‚ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {nodetotal_file}")
                return False

            with open(nodetotal_file, "r", encoding="utf-8") as f:
                node_urls = [line.strip() for line in f if line.strip()]

            # éªŒè¯èŠ‚ç‚¹
            validated_results = await validate_nodes(
                node_urls, output_file=f"result/{date_str}/nodelist_validated.txt"
            )

            # ä¿å­˜éªŒè¯åçš„èŠ‚ç‚¹
            validated_urls = [
                r.url
                for r in validated_results
                if r.is_online and r.quality_score >= 0.6
            ]

            nodelist_file = f"result/{date_str}/nodelist.txt"
            with open(nodelist_file, "w", encoding="utf-8") as f:
                for url in validated_urls:
                    f.write(f"{url}\\n")

            online_count = len(validated_results)
            high_quality_count = len(validated_urls)

            self.logger.info(
                f"èŠ‚ç‚¹éªŒè¯å®Œæˆ: {online_count} ä¸ªåœ¨çº¿ï¼Œ{high_quality_count} ä¸ªé«˜è´¨é‡"
            )
            return True

        except Exception as e:
            self.logger.error(f"éªŒè¯é˜¶æ®µå¤±è´¥: {str(e)}")
            return False

    def show_advanced_status(self):
        """æ˜¾ç¤ºé«˜çº§å·¥ä½œæµçŠ¶æ€"""
        print("ğŸš€ é«˜çº§èŠ‚ç‚¹æ”¶é›†ç³»ç»ŸçŠ¶æ€")
        print("=" * 60)

        # åŸºç¡€çŠ¶æ€
        basic_status = self.get_workflow_status()
        for key, value in basic_status.items():
            if isinstance(value, bool):
                status = "âœ… å°±ç»ª" if value else "âŒ æœªå°±ç»ª"
            else:
                status = value
            print(f"  {key}: {status}")

        # å¤šæºæ”¶é›†å™¨çŠ¶æ€
        print("\\nğŸ“Š å¤šæºæ”¶é›†å™¨çŠ¶æ€:")
        for collector in source_manager.collectors:
            enabled_status = "âœ…" if collector.enabled else "âŒ"
            print(
                f"  {collector.source_name}: {enabled_status} (ä¼˜å…ˆçº§: {collector.priority})"
            )

        # ç¯å¢ƒå˜é‡çŠ¶æ€
        print("\\nğŸ”§ ç¯å¢ƒå˜é‡é…ç½®:")
        env_vars = [
            "TELEGRAM_ENABLED",
            "TELEGRAM_BOT_TOKEN",
            "GITHUB_ENABLED",
            "GITHUB_TOKEN",
        ]

        for var in env_vars:
            value = os.getenv(var)
            if value:
                # éšè—æ•æ„Ÿä¿¡æ¯
                display_value = "***SET***" if "TOKEN" in var else value
                print(f"  {var}: {display_value}")
            else:
                print(f"  {var}: âŒ æœªè®¾ç½®")

        print("=" * 60)


# åˆ›å»ºé«˜çº§å·¥ä½œæµå¼•æ“å®ä¾‹
advanced_workflow = AdvancedWorkflowEngine()


async def run_advanced_collection(sources: Optional[List[str]] = None):
    """è¿è¡Œé«˜çº§æ”¶é›†çš„ä¾¿æ·å‡½æ•°"""
    return await advanced_workflow.run_advanced_collection(sources)


def run_hybrid_workflow(
    sources: Optional[List[str]] = None,
    enable_validation: bool = True,
    update_github: bool = False,
):
    """è¿è¡Œæ··åˆå·¥ä½œæµçš„ä¾¿æ·å‡½æ•°"""
    return advanced_workflow.run_hybrid_workflow(
        sources, enable_validation, update_github
    )


if __name__ == "__main__":
    # æµ‹è¯•é«˜çº§å·¥ä½œæµ
    import asyncio

    # æ˜¾ç¤ºçŠ¶æ€
    advanced_workflow.show_advanced_status()

    # è¿è¡Œæµ‹è¯•
    asyncio.run(run_advanced_collection())
