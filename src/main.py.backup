#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
主程序入口
"""

import sys
import os
import time
from datetime import datetime, timedelta
from src.utils.logger import get_logger
from src.utils.file_handler import FileHandler
from src.testers.connectivity_tester import ConnectivityTester
from config.settings import *
from config.websites import WEBSITES

# 导入各个网站的爬虫
from src.collectors.freeclashnode import FreeClashNodeCollector
from src.collectors.mibei77 import Mibei77Collector
from src.collectors.clashnodev2ray import ClashNodeV2RayCollector
from src.collectors.proxyqueen import ProxyQueenCollector
from src.collectors.wanzhuanmi import WanzhuanmiCollector
from src.collectors.cfmem import CfmemCollector

class NodeCollector:
    """节点收集器主类"""
    
    def __init__(self):
        self.logger = get_logger("main")
        self.file_handler = FileHandler()
        self.connectivity_tester = ConnectivityTester()
        
        # 初始化爬虫
        self.collectors = {
            "freeclashnode": FreeClashNodeCollector(WEBSITES["freeclashnode"]),
            "mibei77": Mibei77Collector(WEBSITES["mibei77"]),
            "clashnodev2ray": ClashNodeV2RayCollector(WEBSITES["clashnodev2ray"]),
            "proxyqueen": ProxyQueenCollector(WEBSITES["proxyqueen"]),
            "wanzhuanmi": WanzhuanmiCollector(WEBSITES["wanzhuanmi"]),
            "cfmem": CfmemCollector(WEBSITES["cfmem"])
        }
        
        self.all_nodes = []
        self.v2ray_subscription_links = []  # 存储链接本身
        self.v2ray_links_with_source = []  # 存储带来源信息的链接
        self.articles_with_source = []
        self.source_info = {}
    
    def collect_all_nodes(self):
        """收集所有网站的节点"""
        self.logger.info("=" * 50)
        self.logger.info("开始收集节点")
        self.logger.info("=" * 50)
        
        start_time = time.time()
        
for site_name, collector in self.collectors.items():
            try:
                self.logger.info(f"正在收集 {site_name} 的节点...")
                
                # 对每个目标日期进行收集
                all_date_nodes = []
                all_date_v2ray_links = []
                all_date_articles = []
                
                for target_date in target_dates:
                    # 重置收集器状态
                    collector.last_article_url = None
                    
                    # 获取指定日期的文章
                    article_url = collector.get_latest_article_url(target_date)
                    if article_url:
                        collector.last_article_url = article_url
                        
                        # 收集节点
                        nodes = collector.collect()
                        all_date_nodes.extend(nodes)
                        
                        # 收集V2Ray订阅链接
                        v2ray_links = collector.get_v2ray_subscription_links(article_url)
                        all_date_nodes.extend(v2ray_links)
                        all_date_v2ray_links.extend(v2ray_links)
                        
                        # 保存文章链接信息
                        all_date_articles.append({
                            'website_name': site_name,
                            'article_url': article_url,
                            'date': target_date.strftime('%Y-%m-%d')
                        })
                
                # 合并所有日期的数据
                nodes = all_date_nodes
                v2ray_links = all_date_v2ray_links
                
                # 保存文章链接信息
                self.articles_with_source.extend(all_date_articles)
                
                # 总是记录V2Ray订阅链接信息
                if not v2ray_links:
                    # 即使没有订阅链接也要记录网站信息
                    self.v2ray_links_with_source.append({
                        'url': '# 无V2Ray订阅链接',
                        'source': site_name,
                        'source_url': collector.last_article_url if hasattr(collector, 'last_article_url') else 'N/A'
                    })
                else:
                    # 添加带来源信息的V2Ray链接
                    for link in v2ray_links:
                        self.v2ray_links_with_source.append({
                            'url': link,
                            'source': site_name,
                            'source_url': collector.last_article_url
                        })
                
                if nodes:
                    self.all_nodes.extend(nodes)
                    nodes.extend(v2ray_links)
                    self.v2ray_subscription_links.extend(v2ray_links)
                    
                    self.source_info[site_name] = {
                        "count": len(nodes),
                        "enabled": collector.enabled,
                        "subscription_links": len(collector.subscription_links),
                        "v2ray_links": len(v2ray_links),
                        "links": collector.subscription_links[:5],  # 只保存前5个链接用于记录
                        "v2ray_link_samples": v2ray_links[:5]  # 只保存前5个V2Ray链接用于记录
                    }
                    self.logger.info(f"{site_name} 收集完成: {len(nodes)} 个节点，{len(v2ray_links)} 个V2Ray订阅链接")
                else:
                    self.source_info[site_name] = {
                        "count": 0,
                        "enabled": collector.enabled,
                        "subscription_links": 0,
                        "v2ray_links": 0,
                        "links": [],
                        "v2ray_link_samples": []
                    }
                    self.logger.warning(f"{site_name} 未收集到节点")
                
                # 请求间隔
                if site_name != list(self.collectors.keys())[-1]:  # 不是最后一个
                    time.sleep(REQUEST_DELAY)
                    
            except Exception as e:
                self.logger.error(f"收集 {site_name} 时出错: {str(e)}")
                self.source_info[site_name] = {
                    "count": 0,
                    "enabled": False,
                    "error": str(e)
                }
        
        # 去重
        original_count = len(self.all_nodes)
        self.all_nodes = list(set(self.all_nodes))
        original_count = len(self.all_nodes)
        
        # 去重V2Ray订阅链接
        original_v2ray_count = len(self.v2ray_subscription_links)
        self.v2ray_subscription_links = list(set(self.v2ray_subscription_links))
        duplicate_count = original_count - len(self.all_nodes)
        
        end_time = time.time()
        duration = end_time - start_time
        
        self.logger.info("=" * 50)
        self.logger.info("节点收集完成")
        self.logger.info(f"总收集时间: {duration:.2f}秒")
        self.logger.info(f"原始节点数: {original_count}")
        self.logger.info(f"去重后节点数: {len(self.all_nodes)}")
        self.logger.info(f"重复节点数: {duplicate_count}")
        self.logger.info(f"原始V2Ray订阅链接数: {original_v2ray_count}")
        self.logger.info(f"去重后V2Ray订阅链接数: {len(self.v2ray_subscription_links)}")
        self.logger.info(f"重复V2Ray订阅链接数: {v2ray_duplicate_count}")
        self.logger.info("=" * 50)
        
        return self.all_nodes
    
    def test_nodes(self, nodes=None):
        """测试节点连通性"""
        if nodes is None:
            nodes = self.all_nodes
        
        if not nodes:
            self.logger.warning("没有节点需要测试")
            return []
        
        self.logger.info("开始测试节点连通性...")
        
        # 备份原始节点
        self.file_handler.backup_nodes(nodes)
        
        # 测试连通性
        valid_nodes = self.tester.test_all_nodes(nodes)
        
        return valid_nodes
    
    def save_results(self, valid_nodes):
        """保存结果"""
        try:
            # 保存V2Ray订阅链接
            v2ray_success = self.file_handler.save_v2ray_links(self.v2ray_links_with_source)
            if not v2ray_success:
                self.logger.warning("V2Ray订阅链接保存失败")
            
            # 保存节点列表
            success = self.file_handler.save_nodes_to_file(valid_nodes)
            if not success:
                return False
            
            # 保存元数据
            self.file_handler.save_nodes_with_metadata(valid_nodes, self.source_info)
            
            # 清理旧备份
            self.file_handler.clean_old_backups()
            
            self.logger.info("结果保存完成")
            return True
            
        except Exception as e:
            self.logger.error(f"保存结果失败: {str(e)}")
            return False
    
    def update_github(self):
        """更新GitHub仓库"""
        try:
            import git
            
            # 获取当前脚本所在目录
            repo_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            
            # 切换到仓库目录
            os.chdir(repo_path)
            
            # Git操作
            repo = git.Repo(repo_path)
            
            # 设置Git配置
            with repo.config_writer() as cw:
                cw.set_value('user', 'email', GIT_EMAIL)
                cw.set_value('user', 'name', GIT_NAME)
            
            # 检查是否有变化
            if repo.is_dirty(untracked_files=True):
                # 添加文件到暂存区
                repo.index.add(['nodelist.txt', 'data/'])
                
                # 获取节点数量用于提交信息
                node_count = len(self.all_nodes)
                valid_count = len([n for n in self.all_nodes if n in self.tester.test_all_nodes(self.all_nodes)])
                
                commit_message = f"更新节点列表 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ({valid_count}/{node_count} 有效)"
                
                # 提交更改
                repo.index.commit(commit_message)
                
                # 推送到远程仓库
                origin = repo.remote(name='origin')
                origin.push()
                
                self.logger.info(f"成功推送到GitHub: {commit_message}")
            else:
                self.logger.info("没有变化需要提交")
            
            return True
            
        except Exception as e:
            self.logger.error(f"更新GitHub失败: {str(e)}")
            return False
    
    def run(self, test_connectivity=True, target_dates=None):
        """运行完整的收集流程"""
        if target_dates is None:
            target_dates = [datetime.now()]
        
        try:
            # 1. 收集所有网站的节点
            all_nodes = self.collect_all_nodes()
            
            # 2. 保存文章链接
            date_suffix = target_dates[0].strftime('%Y%m%d') if len(target_dates) == 1 else None
            webpage_saved = self.file_handler.save_webpage_links(self.articles_with_source, date_suffix)
            if webpage_saved:
                self.logger.info(f"文章链接保存完成")
            else:
                self.logger.error("文章链接保存失败")
            
            # 3. 保存V2Ray订阅链接（无论是否有节点都要保存）
links_saved = self.file_handler.save_subscription_links(self.v2ray_links_with_source, date_suffix)
                if links_saved:
                    self.logger.info(f"订阅链接信息保存完成")            else:
                self.logger.error("V2Ray订阅链接保存失败")
            
            if not all_nodes:
                self.logger.warning("未收集到任何节点")
                return False
            
            # 3. 测试节点连通性
            if test_connectivity:
                self.logger.info("开始测试节点连通性...")
                valid_nodes = self.connectivity_tester.test_nodes(all_nodes)
                self.logger.info(f"连通性测试完成，有效节点: {len(valid_nodes)}")
            else:
                valid_nodes = all_nodes
                self.logger.info("跳过连通性测试")
            
            if not valid_nodes:
                self.logger.warning("没有有效的节点")
                # 即使没有有效节点也要保存订阅链接信息
                links_saved = self.file_handler.save_subscription_links(self.v2ray_links_with_source, date_suffix)
                if links_saved:
                    self.logger.info(f"订阅链接信息保存完成")
                return False
            
            # 4. 按地区分类保存节点
            hk_nodes = []
            other_nodes = []
            
            for node in valid_nodes:
                if self.region_detector.is_hk_node(node):
                    hk_nodes.append(node)
                else:
                    other_nodes.append(node)
            
            # 5. 保存节点到文件
            hk_saved = self.file_handler.save_nodes(hk_nodes, NODELIST_HK_FILE, date_suffix)
            other_saved = self.file_handler.save_nodes(other_nodes, NODELIST_FILE, date_suffix)
            
            if hk_saved and other_saved:
                self.logger.info(f"节点保存完成: 香港节点 {len(hk_nodes)} 个，其他节点 {len(other_nodes)} 个")
            else:
                self.logger.error("节点保存失败")
                return False
            
            # 6. 保存V2Ray订阅链接
            links_saved = self.file_handler.save_subscription_links(self.v2ray_links_with_source, date_suffix)
            if links_saved:
                self.logger.info(f"V2Ray订阅链接保存完成")
            else:
                self.logger.error("V2Ray订阅链接保存失败")
                return False
            
            self.logger.info("收集流程完成")
            return True
            
        except Exception as e:
            self.logger.error(f"运行收集流程时发生错误: {str(e)}")
            return False

def main():
    """主函数"""
    import argparse
    from datetime import datetime, timedelta
    
    parser = argparse.ArgumentParser(description="免费V2Ray节点收集器")
    parser.add_argument("--no-test", action="store_true", help="跳过连通性测试")
    parser.add_argument("--update-github", action="store_true", help="更新GitHub仓库")
    parser.add_argument("--sites", nargs="+", help="指定要收集的网站", choices=list(WEBSITES.keys()))
    parser.add_argument("--date", help="指定日期，格式: YYYY-MM-DD (默认: 今天)")
    parser.add_argument("--dates", nargs="+", help="指定多个日期，格式: YYYY-MM-DD")
    parser.add_argument("--days", type=int, help="获取最近N天的数据")
    
    args = parser.parse_args()
    
    # 处理日期参数
    target_dates = []
    
    if args.dates:
        # 多个日期
        for date_str in args.dates:
            try:
                target_dates.append(datetime.strptime(date_str, "%Y-%m-%d"))
            except ValueError:
                print(f"❌ 无效的日期格式: {date_str}，请使用 YYYY-MM-DD 格式")
                sys.exit(1)
    elif args.days:
        # 最近N天
        today = datetime.now()
        for i in range(args.days):
            target_dates.append(today - timedelta(days=i))
    elif args.date:
        # 单个日期
        try:
            target_dates.append(datetime.strptime(args.date, "%Y-%m-%d"))
        except ValueError:
            print(f"❌ 无效的日期格式: {args.date}，请使用 YYYY-MM-DD 格式")
                sys.exit(1)
    else:
        # 默认今天
        target_dates.append(datetime.now())
    
    # 创建收集器
    collector = NodeCollector()
    
    # 如果指定了特定网站，只启用这些网站
    if args.sites:
        for site_name in collector.collectors:
            if site_name not in args.sites:
                collector.collectors[site_name].enabled = False
                collector.logger.info(f"禁用网站: {site_name}")
    else:
        collector.logger.info("运行所有网站")
    
    # 运行收集
    success = collector.run(
        test_connectivity=not args.no_test,
        target_dates=target_dates
    )    
    if success:
        print("✓ 任务完成")
        sys.exit(0)
    else:
        print("✗ 任务失败")
        sys.exit(1)

if __name__ == "__main__":
    main()